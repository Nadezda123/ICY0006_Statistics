---
title: "Medical Cost Personal Datasets"
output: html_notebook
---

## STAGE 1
#### Step 1

Read your dataset. Done

#### Step 2

Write a description of your dataset:
• What is the topic?

Medical Cost Personal Datasets

• Where you get it from? 

https://www.kaggle.com/mirichoi0218/insurance
Yes, it is open dataset.

• What kind of variables you have (numerical/categorical etc)? Describe the variables (the meaning of those).

Short Descriptions:

The independent variable is manipulated by the experimenter and its effects on the dependent variable are measured.

Qualitative variables (categorical variables) are those that express a qualitative attribute such as hair colour, eye colour, religion, favourite movie, gender, and so on.

Quantitative variables are those variables that are measured in terms of numbers (height, weight, shoe size).

Discrete variables can take only certain values (For example, a household could have three children or six children, but not 4.53 children)

Continuous variables can take any value within the range of the scale (For example, "time to respond to a question" are continuous variables since the scale is continuous,say, the response time could be 1.64 seconds).




AGE - independent continuous variable, quantitative

SEX - categorical

BMI - independent continuous variable, quantitative

Nr of CHILDREN - independent discrete variable, quantitative

SMOKER - independent variable, categorical

REGION - independent variable, categorical

CHARGES -dependent continuous variable, quantitative


#### Step 3

Look for missing values, or errors (NA etc) in the dataset. 

Dataset looks complete

#### Step 4

Do some data visualization (distribution graphs).
```{r}
{echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```
```{r}
str(insurance)
```


```{r}
insurance <- read.csv("insurance.csv", header = TRUE, sep = ",")
hist(insurance$age, xlab = 'age', main = 'Age', col = 'blue', include = TRUE)
```
```{r}
for (i in 1) {
  d <- density(insurance.new[,i])
  plot(d, type="n", main=colnames[i])
  polygon(d, col="red", border="gray")
}
```


```{r}
table(insurance$sex)
```

```{r}
hist(insurance$bmi, xlab = 'bmi', main = 'BMI', col = 'red')
```
```{r}
for (i in 3) {
  d <- density(insurance.new[,i])
  plot(d, type="n", main=colnames[i])
  polygon(d, col="red", border="gray")
}
```



```{r}
hist(insurance$children, xlab = 'children', main = 'Children', col = 'green')
```
```{r}
for (i in 4) {
  d <- density(insurance.new[,i])
  plot(d, type="n", main=colnames[i])
  polygon(d, col="red", border="gray")
}
```



```{r}
table(insurance$region)
```
```{r}
hist(insurance$charges, xlab = 'charges', main = 'Charges', col = 'yellow')
```
```{r}
for (i in 7) {
  d <- density(insurance.new[,i])
  plot(d, type="n", main=colnames[i])
  polygon(d, col="red", border="gray")
}
```
```{r}
#in R we can combine two plots
par(mfrow = c(1,2)) 
par("mar")
par(mar=c(1,1,1,1))
hist(insurance$charges, main = "Histogram of Charges", col = "yellow")
plot(density(insurance$charges), main = "Density plot of Charges")
polygon(density(insurance$charges), col = "red")
```



```{r}
# to examine categorical variables we can use barplot

par(mfrow = c(1,3))
barplot(table(insurance$sex), main = "sex")
barplot(table(insurance$smoker), main = "smoker")
barplot(table(insurance$region), main = "region")


```



#### Step 5

Describe what can you see from those graphs.

Average age 39

Male require insurance more than female

Average BMI is 30.6634, so slightly overweight

Mostly the people doesn't have any children

So basically, if you are old, you smoke and you have extra weight your charges will be the highest:-)


## STAGE 2
#### Step 1

Do some quantitive overview

- compute central tendency measures (mean, mode, median, etc)

Central Tendency- is a typical or central value for a probability distribution.

Mean

It is the sum of all values divided by the total number of values.


Median

It is the middle number in an ordered data set.
```{r}
summary(insurance$age)
```
```{r}
summary(insurance$bmi)
```
```{r}
summary(insurance$children)
```
```{r}
summary(insurance$charges)
```


Mode
The mode is the value that has highest number of occurrences in a set of data. Unlike mean and median, mode can have both numeric and character data (the most frequent value.).

```{r}
# Create the function.
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

getmode(insurance$region)
getmode(insurance$sex)
getmode(insurance$smoker)
getmode(insurance$age)
getmode(insurance$bmi)
getmode(insurance$children)
getmode(insurance$charges)
```

```{r}
#Summary of Central Tendency Measures
summary(insurance)
```


Trimean

It is an estimate of central tendency, and is calculated as a weighted average of the median and the two quartiles of a set of values (weighted average of 25th, 50th and 75th percentils)


- compute variability measures (Range, IQR, Standard Deviation, Variance)

Range
The diffrence between the highest and lowest values
```{r}
range(insurance$age)
```
```{r}
range(insurance$bmi)
```
```{r}
range(insurance$children)
```
```{r}
range(insurance$charges)
```


Interquartile Range
The range of the middle half of a distribution

```{r}
IQR(insurance$age)
```
```{r}
IQR(insurance$bmi)
```

```{r}
IQR(insurance$children)
```
```{r}
IQR(insurance$charges)
```


Standard Deviation
Average distance from the mean
```{r}
head(insurance)
```
```{r}
sapply(insurance[,1:7], sd)
```

```{r}
# to compute Standard deviation we can also use the following formula (we compute the square root of our variance):
  sqrt(var(insurance))
```




Variance
Average of squared distances from the mean.
```{r}
var(insurance)
```




#### Step 2

Write a summary
 
 - What can you use from those central tendency/ variability measures?
 - Does it corresponds to visual picture of distribution?
 - What you can conclude from this analysis?
 
 While a measure of central tendency describes the typical value, measures of variability define how far away the data points tend to fall from the center. The variability in the context of a distribution of values.
 Calculations of central tendency and variability measures corresponds the visual distribution.The conclusion is that data sets could have the same central tendency, but different levels of variability or vice versa. Together they can give us completed picture of our data.
 
 
 
## Stage 3
 
#### Step 1
 
 Try to find out, if there are some linear relationships between variables:
 
- Pick up only those variable, which are suitable. Remove outliers if required.
```{r}
input <- insurance[,c('age','charges')]
print(head(input))
```


```{r}


input <- insurance[,c('age','charges')]
print(head(input))
plot(x = input$age, y = input$charges,
     xlab = "Age",
     ylab = "Charges",
     xlim = c(15, 70),
     ylim = c(1000,15000),
     main = "Age vs Charges"
)
```
In this plot we can see that variables are closely connected. With age increasing the charges are also increased.
Relationship between the independent and dependent variable supposed to be linear, like in our plot.

```{r}
#we can check for outliers by using boxplot
par(mfrow = c(1,3))
par("mar")
par(mar=c(1,1,1,1))
boxplot(insurance$age, main = "Histogram of Age")
boxplot(insurance$bmi, main = "Histogram of BMI")
boxplot(insurance$children, main = "Histogram of Children")
```

Based on boxplot, we can see some outliers in BMI



```{r}
# removing outliers with IQR
# find Q1, Q3 and IQR for values in column Age
Q1 <-quantile(insurance$bmi, .25)
Q3 <- quantile(insurance$bmi, .75)
IQR <- IQR(insurance$bmi)

# only keep rows that have values within 1.5*IQR of Q1 and Q3
insurance_2 <- subset(insurance, insurance$bmi> (Q1 - 1.5*IQR) & insurance$bmi< (Q3 + 1.5*IQR))

#we can compare to the original value that was 1338
str(insurance_2)
```



```{r}
input <- insurance_2[,c('bmi','charges')]
print(head(input))
plot(x = input$bmi, y = input$charges,
     xlab = "BMI",
     ylab = "Charges",
     xlim = c(1, 70),
     ylim = c(1000,60000),
     main = "BMI vs Charges"
)
```
In this plot we can see that relationship is not linear and the high BMI is not affecting the charges significantly. 


```{r}
input <- insurance_2[,c('children','charges')]
print(head(input))
plot(x = input$children, y = input$charges,
     xlab = "Children",
     ylab = "Charges",
     xlim = c(1, 5),
     ylim = c(1000,60000),
     main = "Children vs Charges"
)
```
In this plot we can see that amount of children is slightly affecting the charges, the more children person has the less are the charges.


- Compute correlation matrix. It would be nice if you can express it visually.



```{r}
library("corrplot")
cor(insurance_2[sapply(insurance_2, is.numeric)])

#We can see that the highest correlation based on Pearson, is between Age and Charges

```
```{r}
library(GGally)
library("corrplot")
mat_1 <- as.matrix(cor((insurance_2[sapply(insurance_2, is.numeric)])))
mat_1
corrplot.mixed(cor(mat_1), title = "Correlations between numeric variables", order="hclust", tl.col="black")
```
In this plot the size and shade of each circle represents the strength of each relationship, while the color represents the direction, either negative or positive.



```{r}
# to check the numeric variables relationship
library(PerformanceAnalytics)
chart.Correlation(mat_1, histogram=TRUE, pch=20)
```
In this plot we can see the following information:
- The strength of the relationship.
- The significance of the relationship.
- Histogram with kernel density estimation and rug plot.
- Scatter plot with fitted line.

```{r}
#we can also create another version of complete Scatter plot matrix
library(psych)
pairs.panels(insurance_2[c("age", "sex", "bmi", "children", "smoker", "region")], digits = 2, cor = TRUE, main = "Insurance Matrix")
```
Based on the plot above, we can see that there no strong correlations between the variables, r < 0.2


## Step 2
Pay attention to dependent variable:

- From correlation analysis you know which variables have high correlation with your
dependent variable.

Highest correlation we have is between the Age and the Charges.

- Draw the scatter plots "Dependent variable vs independent variable"

```{r}
input <- insurance_2[,c('age','charges')]

plot(x = input$age, y = input$charges,
     xlab = "Age",
     ylab = "Charges",
     xlim = c(15, 70),
     ylim = c(1000,15000),
     main = "Dependent vs independent variable"
)
```


- Write down your observations
Based on our correlation analyses and scatter plot, we can conclude that these two variables share a common covariance and are homoscedastic.


## Step 3
Pick up one pair of "dependent variable vs independent variable"
- Construct the linear regression model.

Linear Regression is used predict or estimate the value of a dependent variable by modelling it against one or more independent variables.

```{r}
#simple linear regression
data <- lm(insurance_2$charges ~ insurance_2$age)
summary(data)

sigma(data)/mean(insurance_2$charges)


```
F-statistic - Used to estimate the significance of a regression model as a whole. The higher the parameter value, the better it is.
t value - A criteria based on the Student's t distribution. The value of the parameter in linear regression indicates the significance of the factor; it is generally accepted that at t> 2 the factor is significant for the model.
p value - This is the probability that the hypothesis that the independent variables do not explain the dynamics of the dependent variable is true zero. If the p value is below the threshold (.05 or .01 for the most demanding), then the null hypothesis is false. The lower the better)
In our plot the p-value is 2.2e-16, which is 2.2 X 10 ^ -16
If we test with 95% confidence or 5% significance, P-value of 2.2 X 10 ^-16 is very less compared to 5%=0.05. So we will reject the null hypothesis



- Draw the scatter plot "with line"

```{r}
input <- insurance_2[,c('age','charges')]
plot(x = input$age, y = input$charges,
     xlab = "Age",
     ylab = "Charges",
     xlim = c(15, 70),
     ylim = c(1000,15000),
     main = "Age vs Charges")

abline(lm(input$charges ~ input$age, data = insurance_2), col="blue")
linearReg <- lm(input$age ~ input$charges, data = insurance_2)
print(linearReg)
```


```{r}
# On this plot we can see weak relationship
input3<- insurance_2[,c('bmi','charges')]
plot(x = input3$bmi, y = input3$charges,
     xlab = "BMI",
     ylab = "Charges",
     #    xlim = c(1, 70),
     #    ylim = c(1000,60000),
     main = "BMI vs Charges"
)

abline(lm(input3$charges ~ input3$bmi, data = insurance_2), col = "green")
linearReg <- lm(input3$bmi ~ input3$charges, data = insurance_2)
print(linearReg)
```

```{r}

input2 <- insurance_2[,c('children','charges')]
plot(x = input2$children, y = input2$charges,
     xlab = "Children",
     ylab = "Charges",
#    xlim = c(1, 5),
#    ylim = c(1000,60000),
     main = "Children vs Charges"
)
abline(lm(input2$charges ~ input2$children, data = insurance_2), col = "red")
linearReg <- lm(input2$children ~ input2$charges, data = insurance_2)
print(linearReg)
```


```{r}
# as an Example, want to show the plot there are no relationship

input4<- insurance_2[,c('bmi','age')]
plot(x = input4$bmi, y = input4$age,
     xlab = "BMI",
     ylab = "Age",
     #    xlim = c(1, 70),
     #    ylim = c(1000,60000),
     main = "BMI vs Age"
)

abline(lm(input4$age ~ input4$bmi, data = insurance_2), col = "green")
linearReg <- lm(input4$bmi ~ input4$age, data = insurance_2)
print(linearReg)
```

- Write down your observations

If we analyze the highest correlation that we have (Ages and Charges), we can see the positive relationship. When the Age is increasing then we see the Charges are also increasing accordingly. The correlation between them is 0.302 and it is the highest in out table of variables.


## Step 4
- Try regression with several variables, if possible.

```{r}
#multiple regression
#compute the model coefficients
multiple_model <- lm(charges ~ age + sex + bmi + children + smoker + region, data = insurance_2)
summary(multiple_model)
```
Interpretation
The first step in interpreting the multiple regression analysis is to examine the F-statistic and the associated p-value.
In our plot, it can be seen that p-value of the F-statistic is < 2.2e-16 for the Age, which is highly significant. This means that, Age, is one of the predictor variables that significantly related to the outcome variable.
Based on coefficients table we can see that t value evaluates whether or not there is significant association between the predictor and the outcome variable, that is whether the beta coefficient of the predictor is significantly different from zero. Also we can see that changes in Age and less in bmi are associated to changes in charges while changes in children is not significantly associated with sales.

Because children variable is not significant, we can remove it from our model and recreate it without it.

```{r}
#commpute the model coefficients
model <- lm(charges ~ age + bmi, data = insurance_2)
summary(model)

#The error rate can be estimated by dividing the RSE by the mean outcome variable
sigma(model)/mean(insurance$charges)
```
The RSE estimate gives a measure of error of prediction. The lower the RSE, the more accurate the model.
Corresponding to 85% error rate, but still better than in the simple model, where RSE was 86% error rate.

```{r}
#the confidence interval of the model coefficient
confint(model)
```
To assess model accuracy, we have to take a look at other values like R2 and RSE (residual standard error or sigma)
In multiple linear regression, the R2 represents the correlation coefficient between the observed values of the outcome variable (y) and the fitted (i.e., predicted) values of y. For this reason, the value of R will always be positive and will range from zero to one. 
R2 represents the proportion of variance, in the outcome variable y, that may be predicted by knowing the value of the x variables. An R2 value close to 1 indicates that the model explains a large portion of the variance in the outcome variable.
The adjustment in the “Adjusted R Square” value in the summary output is a correction for the number of x variables included in the prediction model.
In our plot, with age and bmi predicator variables, the adjusted R2 = 0,12, meaning that "12% of the variance in the measure of charges can be predicted by age and bmi. In comparison, this model is better than our simple liner regression model with only age, which had an adjusted R2 of 0.09.


- Additional: try other regression algorithms.
 

## Stage 4
#### Step 1

- Pick up a lottery. For example, https://www.eurojackpot.com/ etc. Do not pick up
bingo type lotteries.
- Describe the lottery.
- Describe the winning condition
Step 2
Compute the probabilities of winning for each case. For example, as in here
https://en.wikipedia.org/wiki/Eurojackpot

Step 3
Explain your computation.

Step 4
Write a small report on that.

I am not familiar with lottery games.
So I searched for the most popular lotteries in the world (https://www.wonderslist.com/top-10-best-lottery-games-world/)
I decided to go with US Powerball.

Based on the rules, you must select five numbers from a pool between 1 and 69 and one Powerball between 1 and 26. The Powerball you select can be the same as one of the five main numbers. If you match all five numbers and the Powerball, you win the top prize. By guessing just the main numbers and not the Powerball, you can qualify for the $1 million second prize. The order of the balls is not important, so for my calculations I will use combinations and not permutations.

***C(69,5) = 69!/(5!(69-5)!) = 11238513 So, probability of the wining the prize if you guess 5 numbers is 1/11238513 ≈= 0.000000089
And there are 26 ways to select the Powerball, so resulting in 26 x 11238513 = 292201338 possible selections. The probability to win the main prize, by guessing all 6 numbers is 1/292201338

We  can calculate the rest of the possibilities

***Guessing all five balls but not the Powerball:
25/292201338 ≈= 0.0000000856

***Guessing four of the five balls and the Powerball:
C(5,4) = 5 ways to guess four of the five. The 5th ball is one of the remaining 64 that were not drawn, so C(64,1) = 64 ways for this to happen. There is only 1 way to guess Powerball.
5 x 64 x 1 = 320 ways to guess four of the five balls and Powerball. 
Probability of this to happen is 320/292201338 ≈= 0.0000010951

***Guessing four of the five balls but not the Powerball:
C(5,4) = 5 ways to guess four of the five. The 5th ball is one of the remaining 64 that were not drawn, so C(64,1) = 64 ways for this to happen. This time, there 25 ways to not guess the Powerball.
5 x 64 x 25 = 8000 ways to guess four of the five balls and not the Powerball. 
Probability of this to happen is 8000/292201338 ≈= 0.0000273784

***Guessing three of the five balls and the Powerball:
C(5,3) = 10 ways to guess three of the five. The remaining balls are the ones of the remaining 64 that were not drawn, so C(64,2) = 2016 ways for this to happen. There is only one way to guess Powerball.
10 x 2016 x 1 = 20160 ways to guess three of the five balls and Powerball. 
Probability of this to happen is 20160/292201338 ≈= 0.0000689935

***Guessing three of the five balls but not the Powerball:
C(5,3) = 10 ways to guess three of the five. The remaining balls are the ones of the remaining 64 that were not drawn, so C(64,2) = 2016 ways for this to happen. This time, there 25 ways to not guess the Powerball.
10 x 2016 x 25 = 504000 ways to guess three of the five balls and not the Powerball. 
Probability of this to happen is 504000/292201338 ≈= 0.0017248381

***Guessing two of the five balls and the Powerball:
C(5,2) = 10 ways to guess two of the five. The remaining balls are the ones of the remaining 64 that were not drawn, so C(64,3) = 41664 ways for this to happen. There is only one way to guess Powerball.
10 x 41664 x 1 = 416640 ways to guess two of the five balls and Powerball. 
Probability of this to happen is 416640/292201338 ≈= 0.0014258662

***Guessing one of the five balls and the Powerball:
C(5,4) = 5 ways to guess one of the five. The remaining balls are the ones of the remaining 64 that were not drawn, so C(64,4) = 635376 ways for this to happen. There is only one way to guess Powerball.
5 x 635376 x 1 = 3176880 ways to guess one of the five balls and Powerball. 
Probability of this to happen is 3176880/292201338 ≈= 0.0108722295

Guessing just the Powerball, but none of the other balls:
It is possible to win if non of five balls guessed, but only Powerball guessed. So C(64,5) = 7624512 ways for this to happen. There is only one way to guess Powerball. Meaning that we have 7624512 ways not to guess any balls except for the Powerball.
Probability of this to happen is 7624512/292201338 ≈= 0.0260933507

After calculating the above probabilities of the winning in the US Powerball lottery, I think everyone can see that the chance to win the main price so small that it is close to impossible. Very nice exercise! Now I can advice my friends not to buy the lottery tickets:-)


## Stage 5

#### Step 1
- Split your dataset into two sets: training and testing sets.
- This splitting must be done randomly (if you don't have timeseries as part of the set,
when the process is more complicated)
- The proportions can be different, for example 80/20, 70/30, 90/10, where the bigger
part is the training set, and the smaller part - testing set.

#### Step 2
- Train the regression model on training set.
- You can use different sets of features (if possible), with one or more variables.
- You can train different types of the models (if you wish to try more), but at least
you need to try linear regression.

#### Step 3
- Test you model on testing set.
- Evaluate how "well" your model performs.
- For that you can apply different metrics (MAPE, RMSE, MAE, etc.)
- If it is possible, change the type of the model or set of features, and compare the
results.
- Write report.






 
 
 
 
 
 
 
 









